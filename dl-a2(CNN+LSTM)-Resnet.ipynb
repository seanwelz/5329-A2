{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn            # containing various building blocks for your neural networks\n",
    "import torch.optim as optim      # implementing various optimization algorithms\n",
    "import torch.nn.functional as F  # a lower level (compared to torch.nn) interface\n",
    "\n",
    "# torchvision: popular datasets, model architectures, and common image transformations for computer vision.\n",
    "import torchvision\n",
    "# transforms: transformations useful for image processing\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import glob\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import  Counter\n",
    "#from torchtext import data\n",
    "import gensim.downloader as api\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load caption embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000, 28, 25])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_embeddings = np.load('nlp_embeddings.npy')\n",
    "seq_embeddings = torch.from_numpy(seq_embeddings)\n",
    "seq_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 25])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_embeddings_test = np.load('nlp_embeddings_test.npy')\n",
    "seq_embeddings_test = torch.from_numpy(seq_embeddings_test)\n",
    "seq_embeddings_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_label = pd.read_csv('train.csv')\n",
    "train_label = np.array(df_train_label[['Labels']])\n",
    "train_label_list = []\n",
    "for i in train_label:\n",
    "    for k in i:\n",
    "        train_label_list.append([int(j) for j in k.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(train_label_list)\n",
    "y_train = mlb.transform(train_label_list)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18,\n",
       "       19])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_t = torch.FloatTensor(y_train)\n",
    "y_train_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2data(Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader for MNIST.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 root,labels=None,seq_embeddings=None,\n",
    "                 transform=None,\n",
    "                 preload=False, test=False):\n",
    "        \"\"\" Intialize the MNIST dataset\n",
    "        \n",
    "        Args:\n",
    "            - root: root directory of the dataset\n",
    "            - tranform: a custom tranform function\n",
    "            - preload: if preload the dataset into memory\n",
    "        \"\"\"\n",
    "        self.images = None\n",
    "        if not labels is None:\n",
    "            self.labels = labels\n",
    "        self.seq_embeddings = seq_embeddings\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.test = test    \n",
    "        # read filenames\n",
    "        if self.test == False:\n",
    "            for i in range(30000):\n",
    "                filename = self.root + str(i) + '.jpg'\n",
    "                self.filenames.append(filename)\n",
    "        else:\n",
    "            for i in range(30000,40000):\n",
    "                filename = self.root + str(i) + '.jpg'\n",
    "                self.filenames.append(filename)            \n",
    "\n",
    "        # if preload dataset into memory\n",
    "        if preload:\n",
    "            self._preload()\n",
    "            \n",
    "        self.len = len(self.filenames)\n",
    "                              \n",
    "    def _preload(self):\n",
    "        \"\"\"\n",
    "        Preload dataset to memory\n",
    "        \"\"\"\n",
    "        self.images = []\n",
    "        for image_fn in self.filenames:            \n",
    "            # load images\n",
    "            image = Image.open(image_fn)\n",
    "            self.images.append(image.copy())\n",
    "            # avoid too many opened files bug\n",
    "            image.close()\n",
    "\n",
    "    # probably the most important to customize.\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        if self.test == False:\n",
    "            # If dataset is preloaded\n",
    "            image = self.images[index]\n",
    "            label = self.labels[index]\n",
    "            embeddings = self.seq_embeddings[index]\n",
    "            # May use transform function to transform samples\n",
    "            # e.g., random crop, whitening\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "            # return image and label\n",
    "            return image, label, embeddings\n",
    "        else:\n",
    "            image = self.images[index]\n",
    "            embeddings = self.seq_embeddings[index]\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "            # return image and label\n",
    "            return image, embeddings\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = A2data(\n",
    "    root='data/',labels=y_train_t,seq_embeddings=seq_embeddings,\n",
    "    preload=True, transform=data_transform,test=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = A2data(\n",
    "    root='data/',labels=None, seq_embeddings=seq_embeddings_test,\n",
    "    preload=True, transform=data_transform,test=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.5082, -0.4054, -0.3369,  ..., -0.7650, -0.7308, -0.5596],\n",
       "          [-1.8610, -1.7583, -1.6042,  ..., -0.8164, -0.7479, -0.4568],\n",
       "          [-1.8953, -1.8268, -1.9295,  ..., -0.9192, -0.8335, -0.1657],\n",
       "          ...,\n",
       "          [ 0.7762,  0.9646,  0.3823,  ..., -0.9705, -0.8849, -0.7308],\n",
       "          [ 0.4508,  0.5878,  0.2453,  ..., -0.7650, -0.7308, -0.7822],\n",
       "          [ 0.0569,  0.5536,  0.4508,  ..., -0.7308, -0.7993, -0.9877]],\n",
       " \n",
       "         [[-0.3901, -0.3025, -0.2150,  ..., -1.0378, -1.0028, -0.8102],\n",
       "          [-1.7731, -1.6681, -1.5105,  ..., -1.1078, -1.0553, -0.6176],\n",
       "          [-1.8256, -1.7556, -1.8606,  ..., -1.2654, -1.1078, -0.2325],\n",
       "          ...,\n",
       "          [ 1.0280,  1.1331,  0.0301,  ..., -1.7731, -1.7556, -1.6856],\n",
       "          [ 0.6604,  0.8354, -0.0049,  ..., -1.7031, -1.6856, -1.7031],\n",
       "          [ 0.3102,  0.7304,  0.6954,  ..., -1.7031, -1.7206, -1.7556]],\n",
       " \n",
       "         [[-0.4450, -0.3753, -0.3055,  ..., -1.3513, -1.3339, -1.1770],\n",
       "          [-1.6127, -1.5430, -1.4036,  ..., -1.4036, -1.3513, -0.8807],\n",
       "          [-1.6650, -1.5953, -1.6650,  ..., -1.5256, -1.3861, -0.4798],\n",
       "          ...,\n",
       "          [ 1.0539,  1.1585, -0.3404,  ..., -1.3861, -1.3339, -1.2467],\n",
       "          [ 0.6879,  0.8448, -0.3230,  ..., -1.2816, -1.2467, -1.2816],\n",
       "          [ 0.2871,  0.7402,  0.6356,  ..., -1.2467, -1.2816, -1.3687]]]),\n",
       " tensor([[-8.2492e-01, -3.8849e-01,  5.1727e-01,  6.8471e-01,  3.7141e-01,\n",
       "           4.9418e-01,  2.0886e+00,  8.8538e-04, -9.1597e-01, -6.8480e-01,\n",
       "          -6.9664e-01, -3.3391e-01, -4.4753e+00, -5.1479e-01, -3.3145e-01,\n",
       "          -2.0975e-02,  5.3860e-01, -4.3969e-01, -2.5413e-01, -6.0034e-02,\n",
       "          -1.3038e-02,  6.0605e-01,  2.8161e-01, -4.4357e-01, -2.7380e-01],\n",
       "         [-7.3444e-01, -1.9645e-01,  7.6037e-01,  2.1577e-02,  3.8145e-01,\n",
       "          -2.2441e-01,  2.0073e+00,  4.1696e-01, -6.3872e-01,  1.6142e-01,\n",
       "          -8.6844e-01,  2.8189e-01, -4.7386e+00, -6.3718e-01, -6.2301e-01,\n",
       "           3.2055e-01,  5.4842e-01, -1.0435e+00, -3.2701e-01,  3.5739e-01,\n",
       "           9.5395e-01,  7.0886e-01,  1.5756e-01, -2.2283e-01, -1.5027e-01],\n",
       "         [-4.7110e-01,  4.6011e-01,  5.8961e-01, -1.0114e+00, -3.1605e-01,\n",
       "          -4.7311e-01, -1.5874e+00, -1.6311e+00,  9.5504e-01, -6.2986e-01,\n",
       "          -5.5532e-01,  3.2664e-01, -2.0892e-01, -8.9011e-01,  7.1609e-03,\n",
       "          -4.2201e-01,  1.1694e+00,  2.8130e-01,  1.3778e+00,  6.4949e-01,\n",
       "          -3.7168e-01, -5.6453e-02,  1.4151e-01,  2.9711e-01, -6.2959e-01],\n",
       "         [-6.4197e-01,  5.4905e-01,  9.0568e-01,  1.8736e-01, -9.6757e-01,\n",
       "           9.1092e-02,  2.7984e-01, -1.3125e+00,  6.0704e-03,  1.4671e-01,\n",
       "           4.9866e-01, -8.0051e-01, -1.7158e+00, -1.3234e+00, -2.6242e-01,\n",
       "          -1.8200e-01,  1.9237e+00, -9.1844e-01,  1.1017e+00,  1.3230e+00,\n",
       "          -7.0219e-01, -6.1096e-02, -3.0638e-01,  1.0584e-01,  9.8062e-01],\n",
       "         [-5.9028e-01,  6.3918e-01,  9.9962e-01, -7.4729e-02, -8.8669e-01,\n",
       "          -1.4096e-01,  4.8008e-01, -1.4301e+00, -8.2081e-02, -1.6438e-03,\n",
       "           5.7532e-01, -8.7862e-01, -1.5571e+00, -1.1974e+00, -1.1619e-01,\n",
       "          -4.9941e-02,  1.9210e+00, -8.7735e-01,  1.0141e+00,  1.2833e+00,\n",
       "          -4.7668e-01, -2.9356e-01, -1.5892e-01, -8.0699e-02,  1.0055e+00],\n",
       "         [ 1.2782e-01, -1.3741e+00, -2.6910e-01, -1.8568e+00,  4.3623e-01,\n",
       "           6.4086e-01, -5.8174e-01, -4.6048e-01,  2.9651e-02, -2.1927e-01,\n",
       "           1.0443e+00,  1.0684e+00, -3.0252e+00, -1.1388e+00, -1.5265e-01,\n",
       "          -4.2817e-01,  1.3622e+00, -5.3427e-02, -1.2111e+00, -2.9012e-01,\n",
       "          -1.9759e-02,  7.8843e-01,  1.1146e-01,  4.1190e-03,  1.6901e-01],\n",
       "         [-1.1848e+00,  2.7513e-01,  4.9909e-01,  5.8169e-01,  6.9497e-02,\n",
       "          -7.9172e-02,  6.9749e-01, -1.0830e+00, -1.6125e-01,  5.5638e-01,\n",
       "           1.9053e-01,  5.9271e-01, -3.5420e+00,  1.3479e-01, -3.6436e-01,\n",
       "           2.3156e-01, -3.5137e-01, -1.7598e-01, -2.1793e-01, -9.6499e-01,\n",
       "          -5.6965e-03,  5.3965e-01,  6.5249e-01, -6.6048e-01, -1.0342e+00],\n",
       "         [-3.3765e-02, -1.4936e-01,  9.8664e-01, -5.4995e-02,  6.1311e-01,\n",
       "           2.2440e-01,  8.5409e-01, -3.4288e-01,  8.6147e-01, -1.3989e-01,\n",
       "           1.1262e+00, -4.6733e-03, -3.4966e+00, -4.3862e-01, -3.0749e-01,\n",
       "          -1.4568e-02,  6.3147e-01, -4.6694e-01, -1.5787e-01,  6.1144e-01,\n",
       "          -1.1421e+00, -6.2182e-01,  8.1930e-01,  4.4871e-01,  2.5728e-01],\n",
       "         [-6.4197e-01,  5.4905e-01,  9.0568e-01,  1.8736e-01, -9.6757e-01,\n",
       "           9.1092e-02,  2.7984e-01, -1.3125e+00,  6.0704e-03,  1.4671e-01,\n",
       "           4.9866e-01, -8.0051e-01, -1.7158e+00, -1.3234e+00, -2.6242e-01,\n",
       "          -1.8200e-01,  1.9237e+00, -9.1844e-01,  1.1017e+00,  1.3230e+00,\n",
       "          -7.0219e-01, -6.1096e-02, -3.0638e-01,  1.0584e-01,  9.8062e-01],\n",
       "         [-5.9028e-01,  6.3918e-01,  9.9962e-01, -7.4729e-02, -8.8669e-01,\n",
       "          -1.4096e-01,  4.8008e-01, -1.4301e+00, -8.2081e-02, -1.6438e-03,\n",
       "           5.7532e-01, -8.7862e-01, -1.5571e+00, -1.1974e+00, -1.1619e-01,\n",
       "          -4.9941e-02,  1.9210e+00, -8.7735e-01,  1.0141e+00,  1.2833e+00,\n",
       "          -4.7668e-01, -2.9356e-01, -1.5892e-01, -8.0699e-02,  1.0055e+00],\n",
       "         [-6.3076e-01,  6.0558e-01,  7.0291e-01,  5.6126e-01, -6.9773e-01,\n",
       "           5.3714e-01,  5.2302e-01, -1.4899e+00, -2.0935e-01,  1.5694e-01,\n",
       "           1.0038e+00, -8.4652e-01, -2.4509e+00, -1.2899e+00,  4.4066e-01,\n",
       "          -2.2121e-01,  1.4796e+00, -1.0577e+00,  2.4268e-01,  8.3325e-01,\n",
       "          -4.6005e-01, -5.2612e-01, -8.6866e-02,  3.9713e-01,  1.1537e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_loader = DataLoader(trainset, batch_size=5, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainset_loader)\n",
    "images, labels, embeddings = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 28, 25])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_loader = DataLoader(testset, batch_size=5, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testset_loader)\n",
    "images, embeddings = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split train val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = random_split(trainset, (24000, 6000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 6000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set), len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2513, -0.2342, -0.2171,  ..., -0.0287,  0.9132,  0.9303],\n",
       "          [-0.2513, -0.2342, -0.1999,  ...,  0.7419,  1.3413,  1.1015],\n",
       "          [-0.2342, -0.2171, -0.1828,  ...,  1.0844,  1.2043,  1.4269],\n",
       "          ...,\n",
       "          [ 1.5125,  1.6838,  1.8037,  ...,  1.3413,  1.1872,  1.0159],\n",
       "          [ 1.9578,  2.0948,  2.1462,  ...,  1.5125,  1.3242,  1.1529],\n",
       "          [ 1.8722,  2.0434,  2.1633,  ...,  1.6495,  1.4440,  1.2385]],\n",
       " \n",
       "         [[-1.2304, -1.2129, -1.1954,  ..., -0.4076,  0.4853,  0.5028],\n",
       "          [-1.2129, -1.1954, -1.1779,  ...,  0.3452,  0.9755,  0.6779],\n",
       "          [-1.2129, -1.1779, -1.1604,  ...,  0.6779,  0.8179,  1.0805],\n",
       "          ...,\n",
       "          [ 1.4832,  1.7108,  1.8683,  ...,  1.3256,  1.1331,  0.9230],\n",
       "          [ 2.0959,  2.2360,  2.3060,  ...,  1.5532,  1.3606,  1.1331],\n",
       "          [ 2.0259,  2.2360,  2.3585,  ...,  1.8158,  1.5882,  1.3256]],\n",
       " \n",
       "         [[-1.7696, -1.7696, -1.7696,  ..., -1.1247, -0.3753, -0.4450],\n",
       "          [-1.7696, -1.7522, -1.7522,  ..., -0.4973,  0.0605, -0.2881],\n",
       "          [-1.7522, -1.7522, -1.7696,  ..., -0.2881, -0.1312,  0.1302],\n",
       "          ...,\n",
       "          [ 1.4200,  1.6988,  1.8905,  ...,  1.3154,  1.1062,  0.8622],\n",
       "          [ 2.2043,  2.3786,  2.4657,  ...,  1.5594,  1.3328,  1.0888],\n",
       "          [ 2.1520,  2.3960,  2.5354,  ...,  1.9428,  1.6814,  1.4025]]]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([[ 3.7013e-01, -3.9648e-01, -2.1712e-02, -6.3010e-01, -3.1890e-01,\n",
       "           3.4329e-01,  1.0968e-01,  4.8790e-01, -4.8663e-01,  3.6837e-01,\n",
       "          -3.9179e-01,  2.5414e-01, -4.9282e+00,  6.7597e-02,  3.7147e-01,\n",
       "           3.6817e-01,  1.1655e+00,  9.2116e-02, -8.7735e-01, -7.4562e-01,\n",
       "           4.0903e-01,  1.5672e+00, -2.3879e-01,  2.4755e-01,  7.6386e-01],\n",
       "         [-4.0906e-01,  8.5294e-01, -6.3391e-02, -2.3778e-01, -4.4943e-01,\n",
       "          -9.5257e-02,  1.6011e+00, -1.1824e+00, -3.8148e-02, -8.6246e-02,\n",
       "          -4.0742e-01,  3.7790e-01, -4.8959e+00, -8.3283e-01, -1.4904e-01,\n",
       "           5.4551e-01,  1.7437e-01, -6.5076e-01,  1.3512e-01, -1.5807e+00,\n",
       "           3.8357e-01,  5.3913e-01,  5.2133e-01,  2.7191e-03, -4.8631e-01],\n",
       "         [-3.6896e-01,  7.5151e-01,  2.0904e-01,  8.1553e-01, -7.8291e-01,\n",
       "           7.4906e-01,  1.4803e+00, -1.4017e+00, -4.1383e-02,  5.6439e-01,\n",
       "          -2.4758e-01, -5.4959e-01, -4.3121e+00, -1.2073e+00, -3.2702e-01,\n",
       "          -2.7267e-01,  1.2368e+00, -1.5692e+00,  6.5546e-02, -6.5893e-01,\n",
       "           6.8240e-03,  6.5933e-01,  1.3181e-01,  9.1552e-01,  1.3376e+00],\n",
       "         [-5.7889e-01,  5.2137e-01, -1.7892e-01,  2.2320e-01,  6.1681e-01,\n",
       "           1.7616e-01,  1.6829e+00, -1.3500e+00,  2.7486e-02,  9.5868e-01,\n",
       "           2.2251e-01, -8.2603e-01, -4.3866e+00, -5.5280e-01,  2.0004e-01,\n",
       "          -4.4304e-01,  1.3508e+00, -1.0176e+00,  6.9551e-02,  2.3407e-02,\n",
       "          -2.1827e-01, -5.7156e-01, -7.4594e-01,  2.6706e-01,  9.6434e-01],\n",
       "         [-7.7406e-01, -2.0771e-01,  1.8189e-01,  7.8358e-01, -5.1696e-01,\n",
       "          -1.6024e-01,  7.9916e-02, -1.5990e+00,  8.2508e-01,  8.0804e-01,\n",
       "           5.4208e-01, -7.4552e-02, -2.4497e+00, -5.0365e-01,  2.5041e-01,\n",
       "          -4.5868e-01,  1.0946e+00, -3.2511e-01,  7.0462e-01, -5.0850e-02,\n",
       "          -4.2753e-01,  6.4936e-01,  1.3483e+00, -7.9184e-03,  3.3688e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "imshow(train_set[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, otherwise stick with cpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Conv Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=18):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out, torch.sigmoid(out)\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "\n",
    "    return ResNet(ResidualBlock)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LSTM net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Netrnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Netrnn, self).__init__()\n",
    "        self.lstm = nn.LSTM(25, 32, batch_first =True, bidirectional=True, dropout=0.2)\n",
    "        self.linear = nn.Linear(32*2,18)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        \n",
    "        lstm_out, (h_n,c_n) = self.lstm(sentence)\n",
    "        hidden_out =torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
    "        output = self.linear(hidden_out)\n",
    "        sig_output = torch.sigmoid(output)\n",
    "        \n",
    "        return output, sig_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine two nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Combine, self).__init__()\n",
    "        self.cnn = ResNet18()\n",
    "        self.rnn = Netrnn()\n",
    "        \n",
    "\n",
    "    def forward(self, x, embeddings):\n",
    "        output1, sig_output1 = self.cnn(x)\n",
    "        output2, sig_output2 = self.rnn(embeddings)\n",
    "        output = output1 + output2\n",
    "        sig_output = torch.sigmoid(output)\n",
    "        return output, sig_output\n",
    "    \n",
    "model = Combine().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "valset_loader = DataLoader(val_set, batch_size=100, shuffle=False, num_workers=0)\n",
    "testset_loader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def train(epoch, log_interval=100):\n",
    "      # set training mode\n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        start = time()\n",
    "        for batch_idx, (data, target, embeddings) in enumerate(trainset_loader):\n",
    "            # bring data to the computing device, e.g. GPU\n",
    "            data, target, embeddings = data.to(device), target.to(device), embeddings.float().to(device)\n",
    "\n",
    "            # forward pass\n",
    "            output, sig_x = model(x=data, embeddings=embeddings)\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "          \n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "                \n",
    "            iteration += 1\n",
    "            \n",
    "        model.eval()\n",
    "        outputs, sig_output = model(x=data, embeddings=embeddings)        \n",
    "        pred_result_list = test()\n",
    "        end = time()\n",
    "        print('{:.2f}s'.format(end-start))\n",
    "    return pred_result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()  # set evaluation mode\n",
    "    f1_list = []\n",
    "    pred_result_list = []\n",
    "    with torch.no_grad():\n",
    "        for data, target, embeddings in valset_loader:\n",
    "            data = data.to(device)\n",
    "            embeddings = embeddings.float().to(device)\n",
    "            output, sig_x = model(data, embeddings)\n",
    "            f1_list.append(fbeta_score(target.numpy(), sig_x.cpu().detach().numpy()>0.325,beta=1, average='samples'))\n",
    "    f1_avg = sum(f1_list) / 60\n",
    "    print('Overall F1-Score(samples): ', f1_avg)\n",
    "    return pred_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/24000 (0%)]\tLoss: 0.783832\n",
      "Train Epoch: 0 [6400/24000 (27%)]\tLoss: 0.182566\n",
      "Train Epoch: 0 [12800/24000 (53%)]\tLoss: 0.153438\n",
      "Train Epoch: 0 [19200/24000 (80%)]\tLoss: 0.128349\n",
      "Overall F1-Score(samples):  0.7601090187590189\n",
      "30.05s\n",
      "Train Epoch: 1 [1600/24000 (7%)]\tLoss: 0.119310\n",
      "Train Epoch: 1 [8000/24000 (33%)]\tLoss: 0.117817\n",
      "Train Epoch: 1 [14400/24000 (60%)]\tLoss: 0.114039\n",
      "Train Epoch: 1 [20800/24000 (87%)]\tLoss: 0.116010\n",
      "Overall F1-Score(samples):  0.8079265512265512\n",
      "29.76s\n",
      "Train Epoch: 2 [3200/24000 (13%)]\tLoss: 0.166993\n",
      "Train Epoch: 2 [9600/24000 (40%)]\tLoss: 0.135047\n",
      "Train Epoch: 2 [16000/24000 (67%)]\tLoss: 0.134972\n",
      "Train Epoch: 2 [22400/24000 (93%)]\tLoss: 0.096270\n",
      "Overall F1-Score(samples):  0.8266121693121691\n",
      "29.89s\n",
      "Train Epoch: 3 [4800/24000 (20%)]\tLoss: 0.081860\n",
      "Train Epoch: 3 [11200/24000 (47%)]\tLoss: 0.128622\n",
      "Train Epoch: 3 [17600/24000 (73%)]\tLoss: 0.104215\n",
      "Overall F1-Score(samples):  0.835837313612314\n",
      "30.23s\n",
      "Train Epoch: 4 [0/24000 (0%)]\tLoss: 0.086648\n",
      "Train Epoch: 4 [6400/24000 (27%)]\tLoss: 0.083598\n",
      "Train Epoch: 4 [12800/24000 (53%)]\tLoss: 0.124082\n",
      "Train Epoch: 4 [19200/24000 (80%)]\tLoss: 0.122259\n",
      "Overall F1-Score(samples):  0.8330430495430498\n",
      "29.63s\n",
      "Train Epoch: 5 [1600/24000 (7%)]\tLoss: 0.082921\n",
      "Train Epoch: 5 [8000/24000 (33%)]\tLoss: 0.111860\n",
      "Train Epoch: 5 [14400/24000 (60%)]\tLoss: 0.108034\n",
      "Train Epoch: 5 [20800/24000 (87%)]\tLoss: 0.091587\n",
      "Overall F1-Score(samples):  0.8371811808561809\n",
      "29.59s\n",
      "Train Epoch: 6 [3200/24000 (13%)]\tLoss: 0.094073\n",
      "Train Epoch: 6 [9600/24000 (40%)]\tLoss: 0.097274\n",
      "Train Epoch: 6 [16000/24000 (67%)]\tLoss: 0.071842\n",
      "Train Epoch: 6 [22400/24000 (93%)]\tLoss: 0.108288\n",
      "Overall F1-Score(samples):  0.8405359427609425\n",
      "29.88s\n",
      "Train Epoch: 7 [4800/24000 (20%)]\tLoss: 0.095309\n",
      "Train Epoch: 7 [11200/24000 (47%)]\tLoss: 0.089874\n",
      "Train Epoch: 7 [17600/24000 (73%)]\tLoss: 0.089455\n",
      "Overall F1-Score(samples):  0.8408964405964408\n",
      "29.51s\n",
      "Train Epoch: 8 [0/24000 (0%)]\tLoss: 0.081691\n",
      "Train Epoch: 8 [6400/24000 (27%)]\tLoss: 0.064731\n",
      "Train Epoch: 8 [12800/24000 (53%)]\tLoss: 0.082720\n",
      "Train Epoch: 8 [19200/24000 (80%)]\tLoss: 0.099460\n",
      "Overall F1-Score(samples):  0.8337521645021648\n",
      "29.88s\n",
      "Train Epoch: 9 [1600/24000 (7%)]\tLoss: 0.085245\n",
      "Train Epoch: 9 [8000/24000 (33%)]\tLoss: 0.081633\n",
      "Train Epoch: 9 [14400/24000 (60%)]\tLoss: 0.102558\n",
      "Train Epoch: 9 [20800/24000 (87%)]\tLoss: 0.096299\n",
      "Overall F1-Score(samples):  0.8412562049062052\n",
      "29.59s\n"
     ]
    }
   ],
   "source": [
    "pred_result_list = train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_th():\n",
    "    model.eval()  # set evaluation mode\n",
    "    \n",
    "    pred_result_list = []\n",
    "    th = np.arange(0.20,0.55,0.005)\n",
    "    for t in th:\n",
    "        f1_list = []\n",
    "        with torch.no_grad():\n",
    "            for data, target, embeddings in valset_loader:\n",
    "                data = data.to(device)\n",
    "                embeddings = embeddings.float().to(device)\n",
    "                output, sig_x = model(data, embeddings)\n",
    "                f1_list.append(fbeta_score(target.numpy(), sig_x.cpu().detach().numpy()>t,beta=1, average='samples'))\n",
    "            f1_avg = sum(f1_list) / 60\n",
    "            print('Overall F1-Score(samples): %.4f threshold: %.3f' % (f1_avg, t))\n",
    "    return pred_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_label():\n",
    "    model.eval()  # set evaluation mode\n",
    "    pred_result_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, embeddings in testset_loader:\n",
    "            data = data.to(device)\n",
    "            embeddings = embeddings.float().to(device)            \n",
    "            output, sig_x = model(data, embeddings)\n",
    "            predicted_labels = (sig_x.cpu().detach().numpy() > 0.325).astype(int)\n",
    "            pred_result_list.append(predicted_labels)\n",
    "    return pred_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result_list = test_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.array(pred_result_list).reshape(10000, 18).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = mlb.inverse_transform(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (11,),\n",
       " (1, 9),\n",
       " (1, 9),\n",
       " (1,),\n",
       " (1, 3, 6),\n",
       " (1, 18),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6, 10),\n",
       " (1,),\n",
       " (1, 3, 8),\n",
       " (1,),\n",
       " (1, 3),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (5, 8),\n",
       " (17,),\n",
       " (1, 3, 8),\n",
       " (1, 7),\n",
       " (1, 8, 19),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (5, 8),\n",
       " (1,),\n",
       " (1, 4),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 8),\n",
       " (1,),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (16,),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (11, 18),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (7,),\n",
       " (1,),\n",
       " (16,),\n",
       " (1,),\n",
       " (1, 8),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 15),\n",
       " (1, 3, 10),\n",
       " (1, 16),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6, 8, 10),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (17,),\n",
       " (15, 17),\n",
       " (1,),\n",
       " (1, 13),\n",
       " (7,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1, 17, 18),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6, 8, 10),\n",
       " (5,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (3, 10),\n",
       " (1, 10, 13),\n",
       " (3, 11),\n",
       " (1,),\n",
       " (5,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 18),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 16),\n",
       " (17,),\n",
       " (1, 3, 4),\n",
       " (9,),\n",
       " (1, 3),\n",
       " (1, 3, 8, 10),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 18),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 9),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (15,),\n",
       " (1,),\n",
       " (1, 3, 4, 8),\n",
       " (1, 3, 8),\n",
       " (1,),\n",
       " (1,),\n",
       " (3, 11),\n",
       " (5,),\n",
       " (1, 3, 11),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1, 7),\n",
       " (19,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 5),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6),\n",
       " (1, 3),\n",
       " (1, 18),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3),\n",
       " (5, 8),\n",
       " (1, 18),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 18),\n",
       " (1,),\n",
       " (17,),\n",
       " (1, 7),\n",
       " (16,),\n",
       " (1,),\n",
       " (18,),\n",
       " (1, 15),\n",
       " (1, 9),\n",
       " (1,),\n",
       " (19,),\n",
       " (1,),\n",
       " (1,),\n",
       " (7,),\n",
       " (1, 16),\n",
       " (1, 2, 3, 10),\n",
       " (1, 17),\n",
       " (1,),\n",
       " (1, 3, 8, 10),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (16,),\n",
       " (1,),\n",
       " (1, 15),\n",
       " (1, 2, 3),\n",
       " (1,),\n",
       " (7, 8),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 17),\n",
       " (1, 5, 8),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (16,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 4, 10),\n",
       " (1,),\n",
       " (1,),\n",
       " (5,),\n",
       " (1,),\n",
       " (16,),\n",
       " (1, 3, 6),\n",
       " (5,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (11,),\n",
       " (1,),\n",
       " (1, 3, 8, 10),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 2, 3),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1, 4, 19),\n",
       " (1,),\n",
       " (1,),\n",
       " (7,),\n",
       " (1,),\n",
       " (9,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 9),\n",
       " (18,),\n",
       " (),\n",
       " (1,),\n",
       " (1,),\n",
       " (3, 7),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (7,),\n",
       " (1,),\n",
       " (1,),\n",
       " (7,),\n",
       " (1,),\n",
       " (1, 3, 4),\n",
       " (1, 3, 6),\n",
       " (1,),\n",
       " (1, 3),\n",
       " (1, 3, 6),\n",
       " (1,),\n",
       " (7,),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1, 3, 4, 8),\n",
       " (1,),\n",
       " (1,),\n",
       " (7, 10),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (13,),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1,),\n",
       " (7,),\n",
       " (1,),\n",
       " (3, 11),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6, 10),\n",
       " (5,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 4),\n",
       " (1,),\n",
       " (1, 3, 8, 10),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 8),\n",
       " (7,),\n",
       " (1,),\n",
       " (3, 10),\n",
       " (1,),\n",
       " (1, 3, 10),\n",
       " (1, 9),\n",
       " (1,),\n",
       " (1, 3, 6),\n",
       " (1, 9),\n",
       " (1, 17),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (5,),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1, 3, 4),\n",
       " (3, 10),\n",
       " (1, 3),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 9),\n",
       " (7,),\n",
       " (16,),\n",
       " (1,),\n",
       " (1, 15),\n",
       " (17,),\n",
       " (18, 19),\n",
       " (1, 3, 4),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (15,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 8),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1, 2),\n",
       " (1,),\n",
       " (1, 3),\n",
       " (3, 13),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 5),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (5,),\n",
       " (18,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 9),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6, 8),\n",
       " (1,),\n",
       " (1, 17),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 9),\n",
       " (17,),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (3, 7, 10),\n",
       " (7,),\n",
       " (1,),\n",
       " (1, 3),\n",
       " (1, 3, 10),\n",
       " (1, 3, 18),\n",
       " (1,),\n",
       " (),\n",
       " (1, 6),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 9, 16),\n",
       " (1, 3),\n",
       " (1, 9),\n",
       " (1, 2, 3),\n",
       " (11,),\n",
       " (16,),\n",
       " (1, 15),\n",
       " (1, 3, 4, 8),\n",
       " (1,),\n",
       " (1, 15),\n",
       " (1,),\n",
       " (1, 2, 3),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1, 15),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 7, 15),\n",
       " (1, 3, 10),\n",
       " (3, 13),\n",
       " (1, 2, 3, 8),\n",
       " (1,),\n",
       " (1, 16),\n",
       " (5,),\n",
       " (1, 3, 8),\n",
       " (15, 17),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (1, 5, 8),\n",
       " (1, 3, 18),\n",
       " (1,),\n",
       " (19,),\n",
       " (1, 19),\n",
       " (1, 18),\n",
       " (17, 18),\n",
       " (17,),\n",
       " (1,),\n",
       " (1, 3, 6, 8),\n",
       " (1,),\n",
       " (1, 2, 3, 19),\n",
       " (1,),\n",
       " (16,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6, 7),\n",
       " (1,),\n",
       " (1,),\n",
       " (15,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (5,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 16),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 16),\n",
       " (1,),\n",
       " (1,),\n",
       " (5, 8),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (9,),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1, 16),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 8),\n",
       " (1,),\n",
       " (1,),\n",
       " (3, 13),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 17),\n",
       " (1,),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (7,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (17,),\n",
       " (1, 4, 9, 18),\n",
       " (1,),\n",
       " (1,),\n",
       " (),\n",
       " (1, 3, 6),\n",
       " (1, 8),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 8, 10),\n",
       " (),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 10, 13),\n",
       " (1,),\n",
       " (1, 17),\n",
       " (1,),\n",
       " (17,),\n",
       " (11,),\n",
       " (1,),\n",
       " (19,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 8, 18),\n",
       " (1, 3, 6, 10),\n",
       " (1,),\n",
       " (5,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 10, 11),\n",
       " (3, 10),\n",
       " (1,),\n",
       " (11,),\n",
       " (1, 9),\n",
       " (1,),\n",
       " (1, 15),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 2, 3),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 8, 10),\n",
       " (1,),\n",
       " (1, 3, 4, 8),\n",
       " (1, 3, 6),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1, 3, 18),\n",
       " (1, 3),\n",
       " (1, 2),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 10),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (16,),\n",
       " (5,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3),\n",
       " (1,),\n",
       " (1, 3),\n",
       " (1,),\n",
       " (16, 19),\n",
       " (1, 3, 4),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1, 3, 6),\n",
       " (5, 16),\n",
       " (1, 3, 6),\n",
       " (1,),\n",
       " (1, 3, 8, 10),\n",
       " (1, 19),\n",
       " (1, 3, 6),\n",
       " (1,),\n",
       " (1, 3, 6),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (3, 10, 13),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (16,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (5, 8),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 15),\n",
       " (1, 19),\n",
       " (1, 16),\n",
       " (1,),\n",
       " (1,),\n",
       " (17,),\n",
       " (3, 8),\n",
       " (1, 6),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 8, 10),\n",
       " (1,),\n",
       " (15,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3),\n",
       " (1, 18),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 10),\n",
       " (),\n",
       " (1, 3, 8),\n",
       " (1,),\n",
       " (3, 13),\n",
       " (1,),\n",
       " (1,),\n",
       " (5,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (18,),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (4,),\n",
       " (1,),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 4),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 4, 10),\n",
       " (1,),\n",
       " (1, 9),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (3, 13),\n",
       " (1,),\n",
       " (17,),\n",
       " (1, 9),\n",
       " (1,),\n",
       " (11,),\n",
       " (1,),\n",
       " (1, 18),\n",
       " (3, 11),\n",
       " (1, 3, 8, 10),\n",
       " (11,),\n",
       " (3, 13),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (13,),\n",
       " (1, 18),\n",
       " (1,),\n",
       " (18,),\n",
       " (1, 2),\n",
       " (5,),\n",
       " (1,),\n",
       " (18,),\n",
       " (1, 2, 3),\n",
       " (1, 19),\n",
       " (1, 4),\n",
       " (1,),\n",
       " (1, 15),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 2),\n",
       " (15,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 9),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 4),\n",
       " (1,),\n",
       " (5, 8),\n",
       " (17,),\n",
       " (1, 15),\n",
       " (1, 5),\n",
       " (5,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 9),\n",
       " (18,),\n",
       " (1, 3, 19),\n",
       " (1,),\n",
       " (1, 6),\n",
       " (5, 8),\n",
       " (1,),\n",
       " (1, 3, 4),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (5, 8),\n",
       " (1, 6),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 4),\n",
       " (1,),\n",
       " (17,),\n",
       " (1, 2, 3, 10),\n",
       " (18,),\n",
       " (1,),\n",
       " (1, 5),\n",
       " (1, 5),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (18,),\n",
       " (1, 3, 6),\n",
       " (17,),\n",
       " (1, 3),\n",
       " (1,),\n",
       " (1, 3, 8, 10),\n",
       " (1,),\n",
       " (3, 10),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (17,),\n",
       " (5,),\n",
       " (1, 9),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6),\n",
       " (1, 3),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1, 6),\n",
       " (19,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (16,),\n",
       " (1, 3, 10),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (1, 3),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 19),\n",
       " (3, 8),\n",
       " (1,),\n",
       " (7,),\n",
       " (1,),\n",
       " (11,),\n",
       " (1,),\n",
       " (16,),\n",
       " (1,),\n",
       " (1, 3, 10),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 5),\n",
       " (11,),\n",
       " (17,),\n",
       " (17,),\n",
       " (1, 5),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 17),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1, 11),\n",
       " (18,),\n",
       " (1, 5),\n",
       " (1,),\n",
       " (1, 18),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (1, 5),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (3, 10),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (4,),\n",
       " (1,),\n",
       " (1, 2, 6),\n",
       " (1, 3, 5),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 4),\n",
       " (1, 3, 10, 13),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 3, 6),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (7,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 11),\n",
       " (1,),\n",
       " (3, 11),\n",
       " (1, 3, 19),\n",
       " (15,),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 9),\n",
       " (1, 3, 4),\n",
       " (1,),\n",
       " (7,),\n",
       " (1,),\n",
       " (1, 3, 18),\n",
       " (1,),\n",
       " (1, 3, 5, 8),\n",
       " (1,),\n",
       " (1, 8),\n",
       " (1,),\n",
       " (1, 15),\n",
       " (1, 15),\n",
       " (1, 3, 4),\n",
       " (1,),\n",
       " (9, 16),\n",
       " (15,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (3, 10),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 2, 6),\n",
       " (18,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 9),\n",
       " (1,),\n",
       " (1,),\n",
       " (5,),\n",
       " (1,),\n",
       " (1, 3, 4),\n",
       " (18,),\n",
       " (1,),\n",
       " (17,),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1, 6),\n",
       " (1,),\n",
       " (16,),\n",
       " (1,),\n",
       " (1, 5),\n",
       " (1, 3, 6, 10),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (16,),\n",
       " (1, 3, 19),\n",
       " (1, 4),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 18),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 5),\n",
       " (17,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 5, 8),\n",
       " (1, 8, 18),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (1,),\n",
       " (15,),\n",
       " (1, 16),\n",
       " (1, 3, 8),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 19),\n",
       " (1,),\n",
       " (15,),\n",
       " (1,),\n",
       " (16,),\n",
       " (1,),\n",
       " (18,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1,),\n",
       " (1, 6),\n",
       " (1,),\n",
       " (1, 7),\n",
       " (1,),\n",
       " (1,),\n",
       " ...]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in predicted_labels:\n",
    "    temp = ''\n",
    "    for e in i:\n",
    "        temp += str(e) + ' '\n",
    "    temp = temp.rstrip()\n",
    "    labels.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_temp = pd.DataFrame()\n",
    "Id = [str(i)+'.jpg' for i in range(30000,40000)]\n",
    "result_temp['ImageID'] = Id\n",
    "result_temp['Labels'] = labels\n",
    "result_temp.to_csv('result_temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>39995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>39996.jpg</td>\n",
       "      <td>3 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>39997.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>39998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>39999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ImageID Labels\n",
       "0     30000.jpg      1\n",
       "1     30001.jpg      1\n",
       "2     30002.jpg      1\n",
       "3     30003.jpg      1\n",
       "4     30004.jpg      1\n",
       "...         ...    ...\n",
       "9995  39995.jpg      1\n",
       "9996  39996.jpg    3 4\n",
       "9997  39997.jpg      1\n",
       "9998  39998.jpg      1\n",
       "9999  39999.jpg      1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
